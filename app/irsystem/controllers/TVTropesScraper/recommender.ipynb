{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import json\n",
    "import math\n",
    "import pickle\n",
    "import re\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import defaultdict\n",
    "%matplotlib inline\n",
    "import gensim\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LsiModel\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "import itertools\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.metrics.pairwise import cosine_similarity as cosinesim\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(e,v):\n",
    "    \"\"\"\n",
    "    #Input:\n",
    "    #e = nxd input matrix with n row-vectors of dimensionality d (n is number of dictionary_keys)\n",
    "    #v = mxd input matrix with m row-vectors of dimensionality d (m is number of test samples)\n",
    "    # Output:\n",
    "    # Matrix D of size nxm\n",
    "    # s(i,j) is the cosinesimiarlity of embed(i,:) and test(j,:)\n",
    "    \"\"\"\n",
    "    g=e.dot(v.T)\n",
    "    b=np.expand_dims(np.linalg.norm(e,axis=1),1)+1e-16  # plus this small value to avoid division zero.\n",
    "    a=np.expand_dims(np.linalg.norm(v,axis=1),1)+1e-16  # plus this small value to avoid division zero.\n",
    "    s=np.divide(g,np.multiply(b,a.T))\n",
    "    # ... until here\n",
    "    return s.T\n",
    "def findknn(D,k):\n",
    "    \"\"\"\n",
    "   # D=cos_distance matrix\n",
    "   # k = number of nearest neighbors to be found\n",
    "   # flag =0 , recommend book\n",
    "   # flag =1 , recommend movie\n",
    "    \n",
    "   # Output:\n",
    "   # indices = kxm matrix, where indices(i,j) is the i^th nearest neighbor of xTe(j,:)\n",
    "   # dists = Euclidean distances to the respective nearest neighbors\n",
    "    \"\"\"\n",
    "    \n",
    "    m = D.shape[0]\n",
    "    ind = np.argsort(D, axis=1)\n",
    "    \n",
    "    indices = ind[:,::-1][:,:k]\n",
    "   # print(indices)\n",
    "    r = np.array([_ for _ in range(m)], dtype=np.int)\n",
    "    r = np.array([r] * k).T   \n",
    "    dists = D[r,indices] \n",
    "    return indices,dists\n",
    "\n",
    "def popularity_multiplier(z, strength=1): \n",
    "    \"\"\"A multiplier between 1 to ~1.6 based on a z-score.\"\"\"\n",
    "    z += 4.5\n",
    "    z = min(z, 7)\n",
    "    z = max(z, 2)\n",
    "    return strength*math.log(z/2.0)+1\n",
    "\n",
    "def load_from_json(file_name):\n",
    "    with open(file_name, \"r\") as fp:\n",
    "            json_file=json.load(fp)\n",
    "    return json_file\n",
    "\n",
    "\n",
    "def flattened_list(list_of_lists):\n",
    "    if list_of_lists is None:\n",
    "        return None\n",
    "    flattened = []\n",
    "    for sublist in list_of_lists:\n",
    "        for val in sublist:\n",
    "            flattened.append(val)\n",
    "    return flattened\n",
    "def top_tropes_from_vector(v, n_tropes,col_to_trope_list):\n",
    "    top_dot = np.argsort(-v)[0]\n",
    "\n",
    "    top_tropes = []\n",
    "    for i in top_dot[:n_tropes]:\n",
    "        if v[0][i] != 0:\n",
    "            top_tropes.append(col_to_trope_list[i])\n",
    "    return top_tropes\n",
    "def get_boosted_index_from_summary(query,direction,threshold=0.15):\n",
    "    \"\"\"\n",
    "    # Input:\n",
    "    # query : name of book or movie\n",
    "    # k : number of recomendation \n",
    "    # threshold: boosting if summary tf-idf theshold exceeds the threshold default:0.2\n",
    "    # direction: \n",
    "    # direction = 'mb' : movie - >  books\n",
    "    # direction = 'bm' : book  - >  movies\n",
    "    \n",
    "    # Output:\n",
    "    # index of documents to be boosted\n",
    "    \"\"\"\n",
    "        \n",
    "    if direction == \"mb\":\n",
    "        input_data = movie_summary\n",
    "        input_id2name = movie_id_to_name\n",
    "        input_name2id = movie_name_to_id\n",
    "        output_data =book_summary\n",
    "        output_id2name = book_id_to_name\n",
    "        ouput_name2id = book_name_to_id\n",
    "    elif direction == \"bm\":\n",
    "        input_data = book_summary\n",
    "        input_id2name = book_id_to_name\n",
    "        input_name2id = book_name_to_id\n",
    "        output_data = movie_summary\n",
    "        output_id2name = movie_id_to_name\n",
    "        ouput_name2id = movie_name_to_id\n",
    "    else:\n",
    "        raise Exception(\"Input direction not defined !\")\n",
    "        \n",
    "    query_vec = input_data[[input_name2id[query]]]\n",
    "    \n",
    "\n",
    "    sim = cosine_similarity(output_data,query_vec)\n",
    "    \n",
    "    \n",
    "    boosted_indices= np.where(sim>=threshold)[1]\n",
    "\n",
    "    return boosted_indices\n",
    "\n",
    "'''\n",
    "Returns the k tropes closest to the keyword \n",
    "\n",
    "Inputs: \n",
    "    - keyword: the keyword to search\n",
    "    - dictionary: dictionary of trope words in dataset to search against \n",
    "    - word_to_trope: dictionary mapping word to set of tropes containing the word\n",
    "    - model: the pretrained gensim model\n",
    "    - top_k: number of tropes to return\n",
    "\n",
    "Returns: \n",
    "    - trope_matches: list of the k tropes that are closest to the keyword\n",
    "'''\n",
    "def get_closest_tropes_to_keyword(keyword, dictionary, word_to_trope, model, top_k = 5): \n",
    "    \n",
    "    # check that keyword is in vocabulary \n",
    "    if keyword in model.vocab: \n",
    "        # compute cosine similarity between query and all trope words\n",
    "        all_words = list(dictionary.values())\n",
    "        all_words = [word for word in all_words if word in model.vocab]\n",
    "        dists = model.distances(keyword, all_words)\n",
    "\n",
    "        # sort by similarity in ascending order (0 = perfect similarity)\n",
    "        sorted_indices = np.argsort(dists)\n",
    "        sorted_keyword_match = [all_words[idx] for idx in sorted_indices[:top_k]]\n",
    "\n",
    "   #     print('\\ntop {} matches most similar to `{}`'.format(top_k, keyword))\n",
    "   #     for word in sorted_keyword_match: \n",
    "   #         print('`{}` : {}'.format(word, word_to_trope[word]))\n",
    "\n",
    "        trope_matches = list(itertools.chain.from_iterable([word_to_trope[word] for word in sorted_keyword_match if word in word_to_trope]))\n",
    "    #    print('\\nenhancing search with : {}'.format(trope_matches[:top_k]))\n",
    "\n",
    "        return trope_matches[:top_k]\n",
    "    \n",
    "    else: \n",
    "        print('`{}` not in model vocabulary, cannot enhance search with keyword'.format(keyword))\n",
    "        return []\n",
    "    \n",
    "'''\n",
    "Build a vectorizer and tf-idf matrix corresponding to a dataset\n",
    "\n",
    "Inputs: \n",
    "    - data: dictionary mapping titles to tropes\n",
    "    \n",
    "Returns: \n",
    "    - vectorizer: a vectorizer object \n",
    "    - tf_idf_matrix: a tf-idf matrix corresponding to the topes in the dataset\n",
    "'''\n",
    "def make_tf_idf(data): \n",
    "    \n",
    "    # make a vectorizer based on the 'to' dataset\n",
    "    vectorizer = TfidfVectorizer(analyzer = 'word',\n",
    "                                 tokenizer = lambda x : x, \n",
    "                                 lowercase = False)\n",
    "    tf_idf_matrix = vectorizer.fit_transform(list(data.values()))\n",
    "\n",
    "    return vectorizer, tf_idf_matrix\n",
    "'''\n",
    "build a dataset using tropes \n",
    "\n",
    "Inputs: \n",
    "    - data: dictionary mapping titles to list of tropes\n",
    "\n",
    "Returns: \n",
    "    - dictionary: a bag of words dictionary representation tropes \n",
    "    - word_to_trope: mapping from individual word to tropes that contain the word\n",
    "'''\n",
    "def build_representation_for_tropes(data): \n",
    "    \n",
    "    # build corpus of titles that contain field \n",
    "    corpus = []\n",
    "    word_to_trope = {}\n",
    "    for title, tropes in data.items(): \n",
    "        all_trope_words_for_title = []\n",
    "        for trope in tropes: \n",
    "            trope_words = [word.lower() for word in re.findall('[A-Z][^A-Z]*', trope)]\n",
    "            all_trope_words_for_title.extend(trope_words)\n",
    "            for word in trope_words: \n",
    "                if word in word_to_trope: \n",
    "                    word_to_trope[word].add(trope)\n",
    "                else: \n",
    "                    word_to_trope[word] = set([trope])\n",
    "        corpus.append(all_trope_words_for_title)                                              \n",
    "            \n",
    "    print('{} titles'.format(len(corpus)))\n",
    "        \n",
    "    # build dictionary from corpus\n",
    "    dictionary = Dictionary(corpus)\n",
    "\n",
    "    return dictionary, word_to_trope\n",
    "def print_results(title, keyword, similarity_scores, to_dataset, top_k_titles = 10): \n",
    "    \n",
    "    # sort the scores in descending order\n",
    "    ranked_indices = np.argsort(similarity_scores)[::-1]\n",
    "    \n",
    "    # get list of titles\n",
    "    to_titles = list(to_dataset.keys())\n",
    "\n",
    "    print('\\ntop {} most similar titles to `{}` by trope to keyword `{}` '.format(top_k_titles, title, keyword))\n",
    "    for idx in range(top_k_titles): \n",
    "        print((similarity_scores[ranked_indices[idx]], to_titles[ranked_indices[idx]]))\n",
    "'''\n",
    "Finds the best titles according to tropes based on an input title and keyword. \n",
    "The trope words of the title being searched and the trope words most similar to \n",
    "the keyword are used to find the best matches. Half the number of the tropes corresponding\n",
    "to the title being queried are used to enhance the keyword aspect of the search (eg. if the \n",
    "queried title has 10 tropes associated with it, then the top 5 tropes associated with the \n",
    "keyword will be used to enhance the search. This value seems to result in a good balance)\n",
    "\n",
    "Inputs: \n",
    "    - title: the title being queried\n",
    "    - from_dataset: the dataset corresponding to the title (eg. book dataset if book title)\n",
    "    - keyword: the keyword to search\n",
    "    - dictionary: dictionary representation of trope words associated with each title of desired return type\n",
    "    - word_to_trope: dictionary mapping word to set of tropes containing the word\n",
    "    - to_tf_idf_matrix: tf-idf representation of tropes associated with each title of desired return type\n",
    "    - similarity_matrix: similarity matrix according to tf-idf representation \n",
    "    - model: the pretrained gensim model\n",
    "    \n",
    "Reutrns: \n",
    "    - similarity_scores: numpy array of similarity scores in where the index in the array corresponds\n",
    "                         to the index in the dataset of the media type being recommended\n",
    "'''\n",
    "def best_titles_by_tropes_enhanced(title, from_dataset, keyword, dictionary, word_to_trope, vectorizer, to_tf_idf_matrix, model): \n",
    "    \n",
    "    # get tropes coresponding to title \n",
    "    title_tropes =  from_dataset[title]\n",
    "  #  print('tropes for title `{}` : {}'.format(title, title_tropes))\n",
    "    \n",
    "    # get most similar tropes to keyword, use half the number of tropes in the title to enhance search \n",
    "    top_k_tropes = int(len(title_tropes)/2)\n",
    "    most_similar_tropes = get_closest_tropes_to_keyword(keyword, dictionary, word_to_trope, model, top_k_tropes)\n",
    "    \n",
    "    # extend query to include tropes associated with keyword\n",
    "    query_tropes = most_similar_tropes + title_tropes\n",
    "    \n",
    "   # print('\\ntropes used for final query : {}'.format(query_tropes))\n",
    "    \n",
    "    # generate a query vector \n",
    "    query_vector = vectorizer.transform([query_tropes])\n",
    "    \n",
    "    # compute cosine similarity between query and all titles \n",
    "    similarity_scores = cosinesim(query_vector, to_tf_idf_matrix).flatten()\n",
    "    \n",
    "    return similarity_scores\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./app/irsystem/controllers/TVTropesScraper/Film/Film_tropes_dataset3.json\", 'r') as f:\n",
    "    movie_tropes_data = json.load(f)\n",
    "with open(\"./app/irsystem/controllers/TVTropesScraper/Literature/Literature_tropes_dataset3.json\", 'r') as f:\n",
    "    book_tropes_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./app/irsystem/controllers/DatasetInfo/book_dataset.json\", 'r', encoding='utf-8') as json_file:  \n",
    "    alena_books = json.loads(json_file.read())\n",
    "with open(\"./app/irsystem/controllers/DatasetInfo/movie_dataset.json\", 'r', encoding='utf-8') as json_file:  \n",
    "    alena_movies = json.loads(json_file.read())\n",
    "movielens_reviews = pickle.load(open(\"./app/irsystem/controllers/DatasetInfo/movielens_reviews.p\", \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_id_to_summary=load_from_json(\"./app/irsystem/controllers/DatasetInfo/movie_summary.json\")\n",
    "book_id_to_summary=load_from_json(\"./app/irsystem/controllers/DatasetInfo/book_summary.json\")\n",
    "movie_summary_corpus= [\" \".join(flattened_list(movie_id_to_summary[idx])) if movie_id_to_summary[idx] is not None else \"\" for idx in list(movie_id_to_summary.keys())]\n",
    "book_summary_corpus= [\" \".join(flattened_list(book_id_to_summary[idx]))  if book_id_to_summary[idx] is not None else \"\" for idx in list(book_id_to_summary.keys()) ]\n",
    "# vecterize movie and book\n",
    "vectorizer = TfidfVectorizer(sublinear_tf =True,smooth_idf=True,stop_words=None)\n",
    "vectorizer.fit(movie_summary_corpus+book_summary_corpus)\n",
    "movie_summary=vectorizer.transform(movie_summary_corpus).toarray()\n",
    "book_summary=vectorizer.transform(book_summary_corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted_index_books = defaultdict(list)\n",
    "for book, trope_list in book_tropes_data.items():\n",
    "    for trope in trope_list:\n",
    "        inverted_index_books[trope].append(book)\n",
    "\n",
    "inverted_index_movies = defaultdict(list)\n",
    "for movie, trope_list in movie_tropes_data.items():\n",
    "    for trope in trope_list:\n",
    "        inverted_index_movies[trope].append(movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_titles = []\n",
    "for k, v in alena_movies.items():\n",
    "    movie_titles.append((k, v['idx']))\n",
    "movie_titles.sort(key=lambda pair : pair[1])\n",
    "movie_titles = [k[0] for k in movie_titles]\n",
    "\n",
    "book_titles = []\n",
    "for k, v in alena_books.items():\n",
    "    book_titles.append((k, v['idx']))\n",
    "book_titles.sort(key=lambda pair : pair[1])\n",
    "book_titles = [k[0] for k in book_titles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_tropes = set(inverted_index_movies.keys()) | set(inverted_index_books.keys())\n",
    "# common_tropes = {s.lower() for s in common_tropes}\n",
    "tf_idf = TfidfVectorizer(min_df=3, lowercase=False, vocabulary = common_tropes, norm='l2', use_idf=True, binary=True)\n",
    "movie_by_trope = tf_idf.fit_transform([' '.join(movie_tropes_data[movie_titles[i]]) for i in range(len(movie_titles))]).toarray()\n",
    "book_by_trope = tf_idf.fit_transform([' '.join(book_tropes_data[book_titles[i]]) for i in range(len(book_titles))]).toarray()\n",
    "\n",
    "trope_to_col = tf_idf.vocabulary_\n",
    "col_to_trope_list = tf_idf.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_name_to_id= {movie_titles[i]:i  for i in range(len(movie_titles))}\n",
    "movie_id_to_name= {i:movie_titles[i]  for i in range(len(movie_titles))}\n",
    "book_name_to_id= {book_titles[i]:i  for i in range(len(book_titles))}\n",
    "book_id_to_name= {i:book_titles[i]  for i in range(len(book_titles))}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "movies_popularity = np.zeros(len(movie_titles))\n",
    "books_popularity = np.zeros(len(book_titles))\n",
    "\n",
    "for j in range(len(movie_titles)):\n",
    "    popularity_boost = 0\n",
    "    if movie_titles[j] in movielens_reviews:\n",
    "        z = (movielens_reviews[movie_titles[j]][0]-2000)/8000 # z-score of number of reviews\n",
    "        popularity_boost += popularity_multiplier(z, strength=2)/5\n",
    "        z = (movielens_reviews[movie_titles[j]][1]-3)/0.5  # z-score of 5-star rating\n",
    "        popularity_boost += popularity_multiplier(z, strength=2)/5\n",
    "    movies_popularity[j] = popularity_boost\n",
    "\n",
    "for i in range(len(book_titles)):\n",
    "    popularity_boost = 0\n",
    "    if 'num_reviews' in alena_books[book_titles[i]]:\n",
    "        z = (alena_books[book_titles[i]]['num_reviews']-54)/364\n",
    "        popularity_boost += popularity_multiplier(z, strength=0.3)/2.2\n",
    "    if 'rating' in alena_books[book_titles[i]]:\n",
    "        z = (alena_books[book_titles[i]]['rating']-3)/0.5\n",
    "        popularity_boost += popularity_multiplier(z, strength=0.3)/2.2\n",
    "    books_popularity[i] = popularity_boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2933 titles\n",
      "4797 titles\n"
     ]
    }
   ],
   "source": [
    "model = KeyedVectors.load_word2vec_format('./app/irsystem/controllers/DatasetInfo/gensim_glove.6B.50d.txt', binary = False, limit=50000)\n",
    "# create dictionary representations of datasets\n",
    "book_dictionary, book_word_to_trope = build_representation_for_tropes(book_tropes_data)\n",
    "movie_dictionary, movie_word_to_trope = build_representation_for_tropes(movie_tropes_data)\n",
    "# build book to movie tf-idf matrix\n",
    "book_to_movie_vectorizer, movie_tf_idf = make_tf_idf(movie_tropes_data)\n",
    "# build movie to book tf-idf matrix\n",
    "movie_to_book_vectorizer, book_tf_idf = make_tf_idf(book_tropes_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_not_blank(s):\n",
    "    return bool(s and s.strip())\n",
    "\n",
    "def recommendation(title, keyword=None,k=5,n_tropes=5,direction='mb', popularity_weight=0,boosting=True,relevance_feedback=False):\n",
    "#     mod_mbt = np.where(movie_by_trope==0, -x, movie_by_trope*y)\n",
    "#     mod_bbt = np.where(book_by_trope==0, -x*c, book_by_trope*y*c)\n",
    "    \"\"\"\n",
    "    # Input:\n",
    "    # query : name of book or movie\n",
    "    # k : number of recomendation \n",
    "    # direction: \n",
    "    # direction = 'mb' : movie - >  books\n",
    "    # direction = 'bm' : book  - >  movies\n",
    "    # n_tropes: number of top tropes to be returned and displayed\n",
    "    # popularity_weight: popularity weight\n",
    "    # boosting : apply boosting to tf-idf tropes using tf-idf summary\n",
    "    # relevance_feedback \n",
    "    # keyword: the keyword to search\n",
    "    \n",
    "    # Output:\n",
    "    # recomendations: name of top k of recommended results\n",
    "    # recomendations_scores : scores of top k of recommended results\n",
    "     # recomendations_scores : a nested list of top tropes returned of size : (k * n_tropes)\n",
    "    \"\"\"\n",
    "    if popularity_weight is None: popularity_weight = 0\n",
    "    popularity_weight = float(popularity_weight)\n",
    "    \n",
    "    if direction=='mb':\n",
    "        from_data = movie_tropes_data\n",
    "        to_data=book_tropes_data\n",
    "        input_data = movie_by_trope\n",
    "        input_id2name = movie_id_to_name\n",
    "        input_name2id = movie_name_to_id\n",
    "        output_data = book_by_trope\n",
    "        output_id2name = book_id_to_name\n",
    "        ouput_name2id = book_name_to_id\n",
    "        popularity=books_popularity\n",
    "        word_to_trope = book_word_to_trope\n",
    "        key_word_vectorizer = movie_to_book_vectorizer\n",
    "        key_word_tf_idf_matrix = book_tf_idf\n",
    "        \n",
    "       \n",
    "    elif direction == \"bm\":\n",
    "        from_data = book_tropes_data\n",
    "        to_data=movie_tropes_data\n",
    "        input_data = book_by_trope\n",
    "        input_id2name = book_id_to_name\n",
    "        input_name2id = book_name_to_id\n",
    "        output_data = movie_by_trope\n",
    "        word_to_trope = movie_word_to_trope\n",
    "        output_id2name = movie_id_to_name\n",
    "        word_to_trope = book_word_to_trope\n",
    "        ouput_name2id = movie_name_to_id\n",
    "        popularity=movies_popularity\n",
    "        dictionary = movie_dictionary\n",
    "        word_to_trope = movie_word_to_trope\n",
    "        key_word_vectorizer = book_to_movie_vectorizer\n",
    "        key_word_tf_idf_matrix = movie_tf_idf\n",
    "        \n",
    "    else:\n",
    "        raise Exception(\"Input direction not defined !\")\n",
    "\n",
    "        \n",
    "    if keyword is not None and is_not_blank(keyword):\n",
    "        \n",
    "        key_word_scores = best_titles_by_tropes_enhanced(title, \n",
    "                                                       from_data, \n",
    "                                                       keyword, \n",
    "                                                       dictionary, \n",
    "                                                       word_to_trope, \n",
    "                                                       key_word_vectorizer, \n",
    "                                                       key_word_tf_idf_matrix, \n",
    "                                                       model)\n",
    "        # example to print nice list of ranked results \n",
    "        #print_results(title, keyword, key_word_scores, to_data, 10)\n",
    "   \n",
    "    query_vec = input_data[[input_name2id[title]]]\n",
    "    \n",
    "   \n",
    "    sim = cosine_similarity(output_data,query_vec)\n",
    "\n",
    "    if popularity_weight > 0:\n",
    "        sim = np.multiply(sim, popularity_weight * popularity)\n",
    "\n",
    "    if relevance_feedback:\n",
    "        \n",
    "        indices,scores = findknn(sim,k)\n",
    "        \n",
    "        alpha = 1\n",
    "        beta = 0.75\n",
    "        gamma = 0.15\n",
    "        top_k=2 # choose top 2 as relevant query\n",
    "        \n",
    "        def get_irrevalent(sim,threshold=0):\n",
    "            \"\"\"\n",
    "            # Similarity score <= threshold will be consider as irrelevant docs\n",
    "            \n",
    "            \"\"\"\n",
    "            m = sim.shape[0]\n",
    "            \n",
    "            ind = np.argsort(sim, axis=1)\n",
    "            \n",
    "            ire_ind = np.where(sim<=0)[1]\n",
    "            \n",
    "            return ire_ind\n",
    "        \n",
    "        irrelevant_docs_ids = get_irrevalent(sim)\n",
    "\n",
    "        relevant_docs_ids = indices[0][:top_k] \n",
    "   \n",
    "        modified_query_vec =   alpha * query_vec  \\\n",
    "                             + beta * np.sum(output_data[relevant_docs_ids],axis=0,keepdims=True)/len(relevant_docs_ids) \\\n",
    "                             - gamma * np.sum(output_data[relevant_docs_ids],axis=0,keepdims=True)/len(irrelevant_docs_ids) \n",
    "        \n",
    "        \n",
    "        query_vec = modified_query_vec\n",
    "        sim = cosine_similarity(output_data,query_vec)\n",
    "\n",
    "        indices,scores = findknn(sim,k)\n",
    "        \n",
    "        \n",
    "    if boosting :\n",
    "        boosted_score=0.1\n",
    "        boosted_idx=get_boosted_index_from_summary(title,direction=direction,threshold=0.2)\n",
    "        \n",
    "        if boosted_idx is not None:\n",
    "            for idx in boosted_idx:\n",
    "                 sim[0][idx]=min(sim[0][idx]+boosted_score,1.0) \n",
    "    \n",
    "\n",
    "    no_key_word_score=sim[0]\n",
    " \n",
    "#     print(no_key_word_score)\n",
    "#     print(key_word_scores)\n",
    "  \n",
    "    if keyword is not None and is_not_blank(keyword):\n",
    "        print(keyword)\n",
    "        scores=0.9*key_word_scores+0.1*no_key_word_score\n",
    "    else:\n",
    "        scores=no_key_word_score\n",
    "        \n",
    "    \n",
    "   \n",
    "    ranked_indices,ranked_scores=findknn(np.reshape(scores,newshape=(1,-1)),k)\n",
    "    \n",
    "    \n",
    "    recomendations=[]\n",
    "    recomendation_scores=[]\n",
    "    top_tropes=[]\n",
    "    for i in range(len(ranked_indices[0])):\n",
    "        print (\"{} \\x1b[31m{:.3f}\\x1b[0m\".format(output_id2name[ranked_indices[0][i]], ranked_scores[0][i])) \n",
    "        # print([\"\".join(elem for elem in topNTropes(retrieval[1].get(entry[0]), 5))])\n",
    "        recomendations.append(output_id2name[ranked_indices[0][i]])\n",
    "        recomendation_scores.append(ranked_scores[0][i])\n",
    "        dot=np.multiply(movie_by_trope[[ranked_indices[0][i]]], query_vec[0])\n",
    "        tropes = top_tropes_from_vector(dot,n_tropes,col_to_trope_list)\n",
    "        top_tropes.append(tropes)\n",
    "        \n",
    "        print(tropes)\n",
    "    \n",
    "    return recomendations,recomendation_scores,top_tropes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "monster\n",
      "Harry Potter and the Chamber of Secrets 0.099\n",
      "['GiantSpider', 'CoverIdentityAnomaly', 'BadassLongrobe', 'LiteralCliffHanger', 'LaughingAtYourOwnJokes']\n",
      "Arachnophobia 0.094\n",
      "['OrificeEvacuation', 'SpiderSwarm', 'GiantSpider', 'FacePalm', 'AllForNothing']\n",
      "Monsters, Inc. 0.075\n",
      "['IHaveJustOneThingToSay', 'RewatchBonus', 'AllForNothing', 'MotiveMisidentification', 'WhyDidItHaveToBeSnakes']\n",
      "Beauty and the Beast 0.065\n",
      "['FacePalm', 'BatScare', 'NeverLearnedToRead', 'CoolAndUnusualPunishment', 'ThisIsGonnaSuck']\n",
      "How to Train Your Dragon 0.063\n",
      "['BatScare', 'RewatchBonus', 'ArtisticLicenseBiology', 'WhyDidItHaveToBeSnakes', 'ParentalBonus']\n",
      "Rampage 0.062\n",
      "['TomTheDarkLord', 'ArtisticLicenseBiology', 'RightBehindMe', 'DudeNotFunny', 'ReptilesAreAbhorrent']\n",
      "Godzilla 0.061\n",
      "['GiantSpider', 'MilkyWhiteEyes', 'MindControl', 'DarkerAndEdgier', 'EyeScream']\n",
      "Turbo: A Power Rangers Movie 0.058\n",
      "['MonsterOfTheWeek', 'SentientVehicle', 'FlyingCar', 'PunnyName', 'WeaksauceWeakness']\n",
      "The Craft 0.055\n",
      "['WhyDidItHaveToBeSnakes', 'Narcissist', 'LovePotion', 'PrimalFear', 'ReptilesAreAbhorrent']\n",
      "Monsters vs. Aliens 0.055\n",
      "['ArtisticLicenseBiology', 'ParentalBonus', 'PunnyName', 'BuffySpeak', 'WeaksauceWeakness']\n"
     ]
    }
   ],
   "source": [
    "# example query \n",
    "recomendations,recomendation_scores,top_tropes=recommendation(\"Harry Potter and the Chamber of Secrets\", keyword='monster',k=10,n_tropes=5,direction='bm', popularity_weight=0,boosting=True,relevance_feedback=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vampire\n",
      "Harry Potter and the Chamber of Secrets 0.099\n",
      "['GiantSpider', 'CoverIdentityAnomaly', 'BadassLongrobe', 'LiteralCliffHanger', 'LaughingAtYourOwnJokes']\n",
      "What We Do in the Shadows 0.098\n",
      "['FailedASpotCheck', 'TheDandy', 'CoolAndUnusualPunishment', 'WritersCannotDoMath', 'DisneyDeath']\n",
      "The Hunger 0.096\n",
      "['SlidingScaleOfAdaptationModification', 'BodyHorror', 'AssholeVictim']\n",
      "Arachnophobia 0.094\n",
      "['OrificeEvacuation', 'SpiderSwarm', 'GiantSpider', 'FacePalm', 'AllForNothing']\n",
      "We Own the Night 0.091\n",
      "['EyeScream', 'AntiVillain', 'OhCrap', 'TooDumbToLive']\n",
      "Queen of the Damned 0.086\n",
      "['SealedEvilInACan', 'MrFanservice', 'StalkerWithACrush', 'AntiVillain', 'AdaptedOut']\n",
      "Practical Magic 0.079\n",
      "['MagicMisfire', 'LovePotion', 'LoopholeAbuse', 'EyeScream', 'MindRape']\n",
      "The Craft 0.067\n",
      "['WhyDidItHaveToBeSnakes', 'Narcissist', 'LovePotion', 'PrimalFear', 'ReptilesAreAbhorrent']\n",
      "Twilight 0.066\n",
      "['HarmfulHealing', 'ArtisticLicenseBiology', 'Narm', 'Lampshaded', 'WritersCannotDoMath']\n",
      "Daybreakers 0.066\n",
      "['EpicFail', 'DoesThisRemindYouOfAnything', 'LaserGuidedKarma', 'TheReasonYouSuckSpeech', 'HeelFaceTurn']\n"
     ]
    }
   ],
   "source": [
    "recomendations,recomendation_scores,top_tropes=recommendation(\"Harry Potter and the Chamber of Secrets\", keyword='vampire',k=10,n_tropes=5,direction='bm', popularity_weight=0,boosting=True,relevance_feedback=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Harry Potter and the Chamber of Secrets',\n",
       " 'What We Do in the Shadows',\n",
       " 'The Hunger',\n",
       " 'Arachnophobia',\n",
       " 'We Own the Night',\n",
       " 'Queen of the Damned',\n",
       " 'Practical Magic',\n",
       " 'The Craft',\n",
       " 'Twilight',\n",
       " 'Daybreakers']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recomendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
