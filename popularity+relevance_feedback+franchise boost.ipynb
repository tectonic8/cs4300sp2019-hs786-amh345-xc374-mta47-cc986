{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import json\n",
    "import math\n",
    "import pickle\n",
    "import re\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import defaultdict\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(e,v):\n",
    "    \"\"\"\n",
    "    #Input:\n",
    "    #e = nxd input matrix with n row-vectors of dimensionality d (n is number of dictionary_keys)\n",
    "    #v = mxd input matrix with m row-vectors of dimensionality d (m is number of test samples)\n",
    "    # Output:\n",
    "    # Matrix D of size nxm\n",
    "    # s(i,j) is the cosinesimiarlity of embed(i,:) and test(j,:)\n",
    "    \"\"\"\n",
    "    g=e.dot(v.T)\n",
    "    b=np.expand_dims(np.linalg.norm(e,axis=1),1)+1e-16  # plus this small value to avoid division zero.\n",
    "    a=np.expand_dims(np.linalg.norm(v,axis=1),1)+1e-16  # plus this small value to avoid division zero.\n",
    "    s=np.divide(g,np.multiply(b,a.T))\n",
    "    # ... until here\n",
    "    return s.T\n",
    "def findknn(D,k):\n",
    "    \"\"\"\n",
    "   # D=cos_distance matrix\n",
    "   # k = number of nearest neighbors to be found\n",
    "   # flag =0 , recommend book\n",
    "   # flag =1 , recommend movie\n",
    "    \n",
    "   # Output:\n",
    "   # indices = kxm matrix, where indices(i,j) is the i^th nearest neighbor of xTe(j,:)\n",
    "   # dists = Euclidean distances to the respective nearest neighbors\n",
    "    \"\"\"\n",
    "    \n",
    "    m = D.shape[0]\n",
    "    ind = np.argsort(D, axis=1)\n",
    "    \n",
    "    indices = ind[:,::-1][:,:k]\n",
    "   # print(indices)\n",
    "    r = np.array([_ for _ in range(m)], dtype=np.int)\n",
    "    r = np.array([r] * k).T   \n",
    "    dists = D[r,indices] \n",
    "    return indices,dists\n",
    "\n",
    "def popularity_multiplier(z, strength=1): \n",
    "    \"\"\"A multiplier between 1 to ~1.6 based on a z-score.\"\"\"\n",
    "    z += 4.5\n",
    "    z = min(z, 7)\n",
    "    z = max(z, 2)\n",
    "    return strength*math.log(z/2.0)+1\n",
    "\n",
    "def load_from_json(file_name):\n",
    "    with open(file_name, \"r\") as fp:\n",
    "            json_file=json.load(fp)\n",
    "    return json_file\n",
    "\n",
    "\n",
    "def flattened_list(list_of_lists):\n",
    "    if list_of_lists is None:\n",
    "        return None\n",
    "    flattened = []\n",
    "    for sublist in list_of_lists:\n",
    "        for val in sublist:\n",
    "            flattened.append(val)\n",
    "    return flattened\n",
    "def top_tropes_from_vector(v, n_tropes,col_to_trope_list):\n",
    "    top_dot = np.argsort(-v)[0]\n",
    "\n",
    "    top_tropes = []\n",
    "    for i in top_dot[:n_tropes]:\n",
    "        if v[0][i] != 0:\n",
    "            top_tropes.append(col_to_trope_list[i])\n",
    "    return top_tropes\n",
    "def get_boosted_index_from_summary(query,direction,threshold=0.15):\n",
    "    \"\"\"\n",
    "    # Input:\n",
    "    # query : name of book or movie\n",
    "    # k : number of recomendation \n",
    "    # threshold: boosting if summary tf-idf theshold exceeds the threshold default:0.2\n",
    "    # direction: \n",
    "    # direction = 'mb' : movie - >  books\n",
    "    # direction = 'bm' : book  - >  movies\n",
    "    \n",
    "    # Output:\n",
    "    # index of documents to be boosted\n",
    "    \"\"\"\n",
    "        \n",
    "    if direction == \"mb\":\n",
    "        input_data = movie_summary\n",
    "        input_id2name = movie_id_to_name\n",
    "        input_name2id = movie_name_to_id\n",
    "        output_data =book_summary\n",
    "        output_id2name = book_id_to_name\n",
    "        ouput_name2id = book_name_to_id\n",
    "    elif direction == \"bm\":\n",
    "        input_data = book_summary\n",
    "        input_id2name = book_id_to_name\n",
    "        input_name2id = book_name_to_id\n",
    "        output_data = movie_summary\n",
    "        output_id2name = movie_id_to_name\n",
    "        ouput_name2id = movie_name_to_id\n",
    "    else:\n",
    "        raise Exception(\"Input direction not defined !\")\n",
    "        \n",
    "    query_vec = input_data[[input_name2id[query]]]\n",
    "    \n",
    "\n",
    "    sim = cosine_similarity(output_data,query_vec)\n",
    "    \n",
    "    \n",
    "    boosted_indices= np.where(sim>=threshold)[1]\n",
    "\n",
    "    return boosted_indices\n",
    "\n",
    "def recommendation(title, k=5,n_tropes=5,direction='mb', popularity_weight=0,boosting=True,relevance_feedback=False):\n",
    "#     mod_mbt = np.where(movie_by_trope==0, -x, movie_by_trope*y)\n",
    "#     mod_bbt = np.where(book_by_trope==0, -x*c, book_by_trope*y*c)\n",
    "    \"\"\"\n",
    "    # Input:\n",
    "    # query : name of book or movie\n",
    "    # k : number of recomendation \n",
    "    # direction: \n",
    "    # direction = 'mb' : movie - >  books\n",
    "    # direction = 'bm' : book  - >  movies\n",
    "    # n_tropes: number of top tropes to be returned and displayed\n",
    "    # popularity_weight: popularity weight\n",
    "    # boosting : apply boosting to tf-idf tropes using tf-idf summary\n",
    "    # relevance_feedback \n",
    "    \n",
    "    # Output:\n",
    "    # recomendations: name of top k of recommended results\n",
    "    # recomendations_scores : scores of top k of recommended results\n",
    "     # recomendations_scores : a nested list of top tropes returned of size : (k * n_tropes)\n",
    "    \"\"\"\n",
    "    if popularity_weight is None: popularity_weight = 0\n",
    "    popularity_weight = float(popularity_weight)\n",
    "    \n",
    "    if direction=='mb':\n",
    "        input_data = movie_by_trope\n",
    "        input_id2name = movie_id_to_name\n",
    "        input_name2id = movie_name_to_id\n",
    "        output_data = book_by_trope\n",
    "        output_id2name = book_id_to_name\n",
    "        ouput_name2id = book_name_to_id\n",
    "        popularity=books_popularity\n",
    "    elif direction == \"bm\":\n",
    "        input_data = book_by_trope\n",
    "        input_id2name = book_id_to_name\n",
    "        input_name2id = book_name_to_id\n",
    "        output_data = movie_by_trope\n",
    "        output_id2name = movie_id_to_name\n",
    "        ouput_name2id = movie_name_to_id\n",
    "        popularity=movies_popularity\n",
    "    else:\n",
    "        raise Exception(\"Input direction not defined !\")\n",
    "        \n",
    "        \n",
    "    query_vec = input_data[[input_name2id[query]]]\n",
    "  \n",
    "    sim = cosine_similarity(output_data,query_vec)\n",
    "    \n",
    "\n",
    "    if popularity_weight > 0:\n",
    "        sim = np.multiply(sim, popularity_weight * popularity)\n",
    "\n",
    "    if relevance_feedback:\n",
    "        \n",
    "        indices,scores = findknn(sim,k)\n",
    "        \n",
    "        alpha = 1\n",
    "        beta = 0.75\n",
    "        gamma = 0.15\n",
    "        top_k=2 # choose top 2 as relevant query\n",
    "        \n",
    "        def get_irrevalent(sim,threshold=0):\n",
    "            \"\"\"\n",
    "            # Similarity score <= threshold will be consider as irrelevant docs\n",
    "            \n",
    "            \"\"\"\n",
    "            m = sim.shape[0]\n",
    "            \n",
    "            ind = np.argsort(sim, axis=1)\n",
    "            \n",
    "            ire_ind = np.where(sim<=0)[1]\n",
    "            \n",
    "            return ire_ind\n",
    "        \n",
    "        irrelevant_docs_ids = get_irrevalent(sim)\n",
    "\n",
    "        relevant_docs_ids = indices[0][:top_k] \n",
    "   \n",
    "        modified_query_vec =   alpha * query_vec  \\\n",
    "                             + beta * np.sum(output_data[relevant_docs_ids],axis=0,keepdims=True)/len(relevant_docs_ids) \\\n",
    "                             - gamma * np.sum(output_data[relevant_docs_ids],axis=0,keepdims=True)/len(irrelevant_docs_ids) \n",
    "        \n",
    "        \n",
    "        query_vec = modified_query_vec\n",
    "        sim = cosine_similarity(output_data,query_vec)\n",
    "\n",
    "        indices,scores = findknn(sim,k)\n",
    "        \n",
    "        \n",
    "    if boosting :\n",
    "        boosted_score=0.2\n",
    "        boosted_idx=get_boosted_index_from_summary(query,direction=direction,threshold=0.2)\n",
    "        \n",
    "        if boosted_idx is not None:\n",
    "            for idx in boosted_idx:\n",
    "                 sim[0][idx]=min(sim[0][idx]+boosted_score,1.0) \n",
    "    \n",
    "    indices,scores = findknn(sim,k)   \n",
    "    recomendations=[]\n",
    "    recomendation_scores=[]\n",
    "    top_tropes=[]\n",
    "    for i in range(len(indices[0])):\n",
    "        print (\"{} \\x1b[31m{:.3f}\\x1b[0m\".format(output_id2name[indices[0][i]], scores[0][i])) \n",
    "        # print([\"\".join(elem for elem in topNTropes(retrieval[1].get(entry[0]), 5))])\n",
    "        recomendations.append(output_id2name[indices[0][i]])\n",
    "        recomendation_scores.append(scores[0][i])\n",
    "        dot=np.multiply(movie_by_trope[[indices[0][i]]], query_vec[0])\n",
    "        tropes = top_tropes_from_vector(dot,n_tropes,col_to_trope_list)\n",
    "        top_tropes.append(tropes)\n",
    "        \n",
    "        print(tropes)\n",
    "    \n",
    "    return recomendations,recomendation_scores,top_tropes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"app/irsystem/controllers/TVTropesScraper/Film/Film_tropes_dataset3.json\", 'r') as f:\n",
    "    movie_tropes_data = json.load(f)\n",
    "with open(\"app/irsystem/controllers/TVTropesScraper/Literature/Literature_tropes_dataset3.json\", 'r') as f:\n",
    "    book_tropes_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./app/irsystem/controllers/DatasetInfo/book_dataset.json\", 'r', encoding='utf-8') as json_file:  \n",
    "    alena_books = json.loads(json_file.read())\n",
    "with open(\"./app/irsystem/controllers/DatasetInfo/movie_dataset.json\", 'r', encoding='utf-8') as json_file:  \n",
    "    alena_movies = json.loads(json_file.read())\n",
    "movielens_reviews = pickle.load(open(\"./app/irsystem/controllers/DatasetInfo/movielens_reviews.p\", \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_id_to_summary=load_from_json(\"./app/irsystem/controllers/DatasetInfo/movie_summary.json\")\n",
    "book_id_to_summary=load_from_json(\"./app/irsystem/controllers/DatasetInfo/book_summary.json\")\n",
    "movie_summary_corpus= [\" \".join(flattened_list(movie_id_to_summary[idx])) if movie_id_to_summary[idx] is not None else \"\" for idx in list(movie_id_to_summary.keys())]\n",
    "book_summary_corpus= [\" \".join(flattened_list(book_id_to_summary[idx]))  if book_id_to_summary[idx] is not None else \"\" for idx in list(book_id_to_summary.keys()) ]\n",
    "# vecterize movie and book\n",
    "movie_vectorizer = TfidfVectorizer(sublinear_tf =True,smooth_idf=True,stop_words=None)\n",
    "movie_vectorizer.fit(movie_summary_corpus+book_summary_corpus)\n",
    "movie_summary=movie_vectorizer.transform(movie_summary_corpus).toarray()\n",
    "book_summary=movie_vectorizer.transform(book_summary_corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted_index_books = defaultdict(list)\n",
    "for book, trope_list in book_tropes_data.items():\n",
    "    for trope in trope_list:\n",
    "        inverted_index_books[trope].append(book)\n",
    "\n",
    "inverted_index_movies = defaultdict(list)\n",
    "for movie, trope_list in movie_tropes_data.items():\n",
    "    for trope in trope_list:\n",
    "        inverted_index_movies[trope].append(movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_titles = []\n",
    "for k, v in alena_movies.items():\n",
    "    movie_titles.append((k, v['idx']))\n",
    "movie_titles.sort(key=lambda pair : pair[1])\n",
    "movie_titles = [k[0] for k in movie_titles]\n",
    "\n",
    "book_titles = []\n",
    "for k, v in alena_books.items():\n",
    "    book_titles.append((k, v['idx']))\n",
    "book_titles.sort(key=lambda pair : pair[1])\n",
    "book_titles = [k[0] for k in book_titles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_tropes = set(inverted_index_movies.keys()) | set(inverted_index_books.keys())\n",
    "# common_tropes = {s.lower() for s in common_tropes}\n",
    "tf_idf = TfidfVectorizer(min_df=3, lowercase=False, vocabulary = common_tropes, norm='l2', use_idf=True, binary=True)\n",
    "movie_by_trope = tf_idf.fit_transform([' '.join(movie_tropes_data[movie_titles[i]]) for i in range(len(movie_titles))]).toarray()\n",
    "book_by_trope = tf_idf.fit_transform([' '.join(book_tropes_data[book_titles[i]]) for i in range(len(book_titles))]).toarray()\n",
    "\n",
    "trope_to_col = tf_idf.vocabulary_\n",
    "col_to_trope_list = tf_idf.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_name_to_id= {movie_titles[i]:i  for i in range(len(movie_titles))}\n",
    "movie_id_to_name= {i:movie_titles[i]  for i in range(len(movie_titles))}\n",
    "book_name_to_id= {book_titles[i]:i  for i in range(len(book_titles))}\n",
    "book_id_to_name= {i:book_titles[i]  for i in range(len(book_titles))}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "movies_popularity = np.zeros(len(movie_titles))\n",
    "books_popularity = np.zeros(len(book_titles))\n",
    "\n",
    "for j in range(len(movie_titles)):\n",
    "    popularity_boost = 0\n",
    "    if movie_titles[j] in movielens_reviews:\n",
    "        z = (movielens_reviews[movie_titles[j]][0]-2000)/8000 # z-score of number of reviews\n",
    "        popularity_boost += popularity_multiplier(z, strength=2)/5\n",
    "        z = (movielens_reviews[movie_titles[j]][1]-3)/0.5  # z-score of 5-star rating\n",
    "        popularity_boost += popularity_multiplier(z, strength=2)/5\n",
    "    movies_popularity[j] = popularity_boost\n",
    "\n",
    "for i in range(len(book_titles)):\n",
    "    popularity_boost = 0\n",
    "    if 'num_reviews' in alena_books[book_titles[i]]:\n",
    "        z = (alena_books[book_titles[i]]['num_reviews']-54)/364\n",
    "        popularity_boost += popularity_multiplier(z, strength=0.3)/2.2\n",
    "    if 'rating' in alena_books[book_titles[i]]:\n",
    "        z = (alena_books[book_titles[i]]['rating']-3)/0.5\n",
    "        popularity_boost += popularity_multiplier(z, strength=0.3)/2.2\n",
    "    books_popularity[i] = popularity_boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harry Potter and the Chamber of Secrets\n",
      "-------------------------\n",
      "bookTomovie\n",
      "Harry Potter and the Chamber of Secrets \u001b[31m0.593\u001b[0m\n",
      "['GiantSpider', 'CoverIdentityAnomaly', 'BadassLongrobe', 'LiteralCliffHanger', 'LaughingAtYourOwnJokes']\n",
      "Arachnophobia \u001b[31m0.399\u001b[0m\n",
      "['OrificeEvacuation', 'SpiderSwarm', 'GiantSpider', 'FacePalm', 'AllForNothing']\n",
      "Harry Potter and the Goblet of Fire \u001b[31m0.273\u001b[0m\n",
      "['ArtisticLicenseBiology', 'EpicRocking', 'AdaptationInducedPlothole', 'INeverSaidItWasPoison', 'BalefulPolymorph']\n",
      "Harry Potter and the Prisoner of Azkaban \u001b[31m0.261\u001b[0m\n",
      "['EpicRocking', 'AdaptationInducedPlothole', 'BodyHorror', 'BalefulPolymorph', 'DarkerAndEdgier']\n",
      "Harry Potter and the Half-Blood Prince \u001b[31m0.250\u001b[0m\n",
      "['AdaptationInducedPlothole', 'AdaptationExplanationExtrication', 'NiceJobFixingItVillain', 'AscendedExtra', 'RedHerring']\n",
      "\n",
      "Heart Of Darkness\n",
      "-------------------------\n",
      "bookTomovie\n",
      "Tarzan \u001b[31m0.402\u001b[0m\n",
      "['HollywoodNatives', 'HungryJungle', 'DarkestAfrica', 'JunglePrincess', 'SignatureRoar']\n",
      "The Last Samurai \u001b[31m0.396\u001b[0m\n",
      "['HollywoodNatives', 'ATeamFiring', 'ApatheticCitizens', 'GoingNative', 'KillEmAll']\n",
      "Gorillas in the Mist \u001b[31m0.105\u001b[0m\n",
      "['GoingNative', 'PrimalChestPound', 'EvilPoacher', 'EverythingsBetterWithMonkeys', 'BadassBookworm']\n",
      "The Legend of Tarzan \u001b[31m0.097\u001b[0m\n",
      "['DarkestAfrica', 'SignatureRoar', 'LoinCloth', 'BarbarianLonghair', 'CompositeCharacter']\n",
      "Apocalypse Now \u001b[31m0.094\u001b[0m\n",
      "['SendInTheSearchTeam', 'RiverOfInsanity', 'GoMadFromTheRevelation', 'SceneryGorn', 'FamousLastWords']\n",
      "\n",
      "Romeo And Juliet\n",
      "-------------------------\n",
      "bookTomovie\n",
      "Romeo and Juliet \u001b[31m1.000\u001b[0m\n",
      "['YoungLoveVersusOldHate', 'BromanticFoil', 'BalconyWooingScene', 'CargoEnvy', 'TheFightingNarcissist']\n",
      "West Side Story \u001b[31m0.372\u001b[0m\n",
      "['YoungLoveVersusOldHate', 'BalconyWooingScene', 'EnterStageWindow', 'ATragedyOfImpulsiveness', 'DanceOfRomance']\n",
      "William Shakespeare's Romeo + Juliet \u001b[31m0.118\u001b[0m\n",
      "['PrinceCharmless', 'TheDyingWalk', 'DyingCurse', 'MasqueradeBall', 'ModestyBedsheet']\n",
      "Gettysburg \u001b[31m0.085\u001b[0m\n",
      "['CourtlyLove', 'TheCassandra', 'TragicHero', 'GallowsHumor', 'AgeLift']\n",
      "The Merchant of Venice \u001b[31m0.084\u001b[0m\n",
      "['MaidAndMaiden', 'Elopement', 'PungeonMaster', 'HotBlooded', 'FreudianTrio']\n",
      "\n",
      "The Hunger Games\n",
      "-------------------------\n",
      "bookTomovie\n",
      "The Hunger Games \u001b[31m0.630\u001b[0m\n",
      "['PresidentEvil', 'AfterActionHealingDrama', 'ChildrenForcedToKill', 'DeadlyGame', 'EverythingTryingToKillYou']\n",
      "The Hunger Games: Mockingjay - Part 2 \u001b[31m0.427\u001b[0m\n",
      "['PresidentEvil', 'VoiceOfTheResistance', 'EverythingTryingToKillYou', 'HerHeartWillGoOn', 'DeathCourse']\n",
      "The Hunger Games: Mockingjay - Part 1 \u001b[31m0.427\u001b[0m\n",
      "['PresidentEvil', 'VoiceOfTheResistance', 'EverythingTryingToKillYou', 'HerHeartWillGoOn', 'DeathCourse']\n",
      "The Hunger Games: Catching Fire \u001b[31m0.136\u001b[0m\n",
      "['PresidentEvil', 'EverythingTryingToKillYou', 'ForcedToWatch', 'FogOfDoom', 'ManiacMonkeys']\n",
      "Snowpiercer \u001b[31m0.122\u001b[0m\n",
      "['TheRevolutionWillNotBeCivilized', 'FirstWorldProblems', 'NotInThisForYourRevolution', 'NeckSnap', 'NecessarilyEvil']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "titles = [\"Harry Potter and the Chamber of Secrets\", 'Heart Of Darkness', 'Romeo And Juliet', 'The Hunger Games']\n",
    "for query in titles:\n",
    "    print(query)\n",
    "    print(\"-------------------------\")\n",
    "    print(\"bookTomovie\")   \n",
    "    names,recomendation_scores,top_tropes=recommendation(query,direction=\"bm\",popularity_weight=0,boosting=True,relevance_feedback=True)\n",
    "    print()\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Hunger Games',\n",
       " 'The Hunger Games: Mockingjay - Part 2',\n",
       " 'The Hunger Games: Mockingjay - Part 1',\n",
       " 'The Hunger Games: Catching Fire',\n",
       " 'Snowpiercer']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6296697813833947,\n",
       " 0.426556792160219,\n",
       " 0.426556792160219,\n",
       " 0.13597624654165127,\n",
       " 0.12206583195133926]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recomendation_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['PresidentEvil',\n",
       "  'AfterActionHealingDrama',\n",
       "  'ChildrenForcedToKill',\n",
       "  'DeadlyGame',\n",
       "  'EverythingTryingToKillYou'],\n",
       " ['PresidentEvil',\n",
       "  'VoiceOfTheResistance',\n",
       "  'EverythingTryingToKillYou',\n",
       "  'HerHeartWillGoOn',\n",
       "  'DeathCourse'],\n",
       " ['PresidentEvil',\n",
       "  'VoiceOfTheResistance',\n",
       "  'EverythingTryingToKillYou',\n",
       "  'HerHeartWillGoOn',\n",
       "  'DeathCourse'],\n",
       " ['PresidentEvil',\n",
       "  'EverythingTryingToKillYou',\n",
       "  'ForcedToWatch',\n",
       "  'FogOfDoom',\n",
       "  'ManiacMonkeys'],\n",
       " ['TheRevolutionWillNotBeCivilized',\n",
       "  'FirstWorldProblems',\n",
       "  'NotInThisForYourRevolution',\n",
       "  'NeckSnap',\n",
       "  'NecessarilyEvil']]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_tropes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Hunger Games\n",
      "-------------------------\n",
      "movieTobook\n",
      "The Hunger Games \u001b[31m0.626\u001b[0m\n",
      "['EvilGloating', 'DueToTheDead', 'Squick', 'TheDitz', 'JumpScare']\n",
      "Miss Peregrine's Home for Peculiar Children \u001b[31m0.393\u001b[0m\n",
      "['OohMeAccentsSlipping', 'NotSoDifferent', 'KarmicDeath', 'OhCrap', 'LargeHam']\n",
      "Macbeth \u001b[31m0.097\u001b[0m\n",
      "['FoodPorn', 'HeldGaze', 'AscendedExtra', 'LightIsNotGood', 'DemotedToExtra']\n",
      "Vampire Huntress Legend \u001b[31m0.088\u001b[0m\n",
      "['DiedInYourArmsTonight', 'RaceLift', 'AscendedExtra', 'AdaptationExpansion', 'SparedByTheAdaptation']\n",
      "Codex Alera \u001b[31m0.088\u001b[0m\n",
      "['BigNo', 'OhCrap', 'LargeHam', 'InterruptedSuicide', 'RunningGag']\n",
      "\n",
      "The Emperor's Club\n",
      "-------------------------\n",
      "movieTobook\n",
      "One Fine Day In The Middle Of The Night \u001b[31m0.451\u001b[0m\n",
      "['AntiHero']\n",
      "Bend Sinister \u001b[31m0.445\u001b[0m\n",
      "['BerserkButton', 'MeaningfulName']\n",
      "The Wish List \u001b[31m0.138\u001b[0m\n",
      "['BrokenPedestal', 'ChekhovsGun', 'BerserkButton', 'MeaningfulName', 'ShoutOut']\n",
      "The Kite Runner \u001b[31m0.104\u001b[0m\n",
      "['AnAesop', 'Egopolis', 'ChekhovsGun', 'WellDoneSonGuy', 'CassandraTruth']\n",
      "The Eye Of The Heron \u001b[31m0.104\u001b[0m\n",
      "['BerserkButton', 'ShoutOut']\n",
      "\n",
      "Titanic\n",
      "-------------------------\n",
      "movieTobook\n",
      "The Poseidon Adventure \u001b[31m0.404\u001b[0m\n",
      "['AsYouKnow', 'DirtyCoward', 'ArtisticLicenseHistory', 'CassandraTruth', 'JerkassHasAPoint']\n",
      "A Little Princess \u001b[31m0.404\u001b[0m\n",
      "['AdultFear', 'FormerlyFat', 'ChekhovsSkill']\n",
      "The Devil's Arithmetic \u001b[31m0.104\u001b[0m\n",
      "['FightToSurvive', 'RageAgainstTheHeavens', 'DwindlingParty', 'EarnYourHappyEnding', 'MyGodWhatHaveIDone']\n",
      "The Perfect Storm \u001b[31m0.096\u001b[0m\n",
      "['GettingCrapPastTheRadar', 'ShownTheirWork', 'WhatHappenedToTheMouse', 'DeathByAdaptation', 'SettingUpdate']\n",
      "Ivanhoe \u001b[31m0.092\u001b[0m\n",
      "['UglyGuyHotWife', 'TitleDrop']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "titles = ['The Hunger Games', \"The Emperor's Club\", 'Titanic']\n",
    "for query in titles:  \n",
    "    print(query)\n",
    "    print(\"-------------------------\")\n",
    "    print(\"movieTobook\")   \n",
    "    names,recomendation_scores,top_tropes=recommendation(query,direction=\"mb\",popularity_weight=0,boosting=True,relevance_feedback=True)\n",
    "    print()\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
